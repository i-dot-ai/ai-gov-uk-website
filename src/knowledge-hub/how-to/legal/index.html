<!DOCTYPE html><html lang="en" data-astro-cid-sckkx6r4> <head><meta charset="utf-8"><meta content="width=device-width, initial-scale=1.0" name="viewport"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="preload" href="/fonts/static/Inter-Regular.ttf" as="font" type="font/ttf" crossorigin="anonymous"><link rel="preload" href="/fonts/static/Inter-Medium.ttf" as="font" type="font/ttf" crossorigin="anonymous"><title>
			Legal concerns - 
			AI Knowledge Hub
		</title><meta property="og:title" content="Legal concerns"><meta property="og:type" content="website"><meta property="og:url" content="https://ai.gov.uk/knowledge-hub/"><meta property="og:description" content="Find tools, prompts and how-to guides for teams adopting AI technologies in the UK government"><meta property="og:site_name" content="AI Knowledge Hub"><meta property="og:image" content="https://ai.gov.uk/img/knowledge-hub-banner.png"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@i_dot_ai"><meta name="twitter:title" content="Legal concerns"><meta name="twitter:description" content="Find tools, prompts and how-to guides for teams adopting AI technologies in the UK government"><meta name="twitter:image" content="https://ai.gov.uk/img/knowledge-hub-banner.png"><link href="/img/favicon.ico" rel="icon"><link href="/img/apple-touch-icon.png" rel="apple-touch-icon"><link rel="stylesheet" href="https://rsms.me/inter/inter.css"><script type="module" src="https://cdn.jsdelivr.net/gh/lit/dist@3/core/lit-core.min.js"></script><script type="module" src="/_astro/Layout.astro_astro_type_script_index_0_lang.uKs0OfS_.js"></script><script defer data-domain="ai.gov.uk" src="https://plausible.io/js/script.pageview-props.tagged-events.outbound-links.file-downloads.js"></script><script>(function(){const posthogKey = "phc_HQYS98bU7UxEA581h5DytBmvbncBVR79TGuYZQO5mds";

			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init Te Ds js Re Os As capture Ke calculateEventProperties zs register register_once register_for_session unregister unregister_for_session Hs getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey displaySurvey canRenderSurvey canRenderSurveyAsync identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty qs Ns createPersonProfile Bs Cs Ws opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing get_explicit_consent_status is_capturing clear_opt_in_out_capturing Ls debug L Us getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
			posthog.init(posthogKey, {
				cookieless_mode: 'always',	
				api_host: 'https://eu.i.posthog.com',
				defaults: '2025-05-24',
			})
		})();</script><link rel="stylesheet" href="/_astro/about.C3ZOaQH8.css">
<style>.kh-back-to-top[data-astro-cid-qrl4wijt]{display:none}.kh-back-to-top__icon[data-astro-cid-qrl4wijt]{margin-right:10px}@media (min-width: 641px){.kh-back-to-top[data-astro-cid-qrl4wijt]{display:block;flex-shrink:0;padding-top:1.5rem;padding-bottom:.5rem}}
</style></head> <body class="govuk-template__body govuk-frontend-supported" data-astro-cid-sckkx6r4> <a class="govuk-skip-link" data-module="govuk-skip-link" href="#main" data-astro-cid-sckkx6r4>Skip to main content</a> <header> <div class="govuk-header govuk-header--full-width-border" data-module="govuk-header"> <div class="govuk-header__container govuk-width-container"> <div class="govuk-header__logo"> <a href="/" class="govuk-header__link govuk-header__link--homepage"> <span style="font-weight: bold;">AI.GOV.UK</span> <span class="govuk-header__product-name">Knowledge Hub</span> </a> </div> <div class="govuk-header__content"> <nav aria-label="Menu" class="govuk-header__navigation"> <button id="header-toggle-button" type="button" class="govuk-header__menu-button govuk-js-header-toggle" aria-controls="navigation" aria-expanded="false">Menu</button> <ul id="navigation" class="govuk-header__navigation-list"> <li class="govuk-header__navigation-item"> <a class="govuk-header__link" href="/about"> About </a> </li><li class="govuk-header__navigation-item"> <a class="govuk-header__link" href="/tools"> Tools </a> </li><li class="govuk-header__navigation-item"> <a class="govuk-header__link" href="/prompts"> Prompts </a> </li><li class="govuk-header__navigation-item"> <a class="govuk-header__link" href="/how-tos"> How-tos </a> </li> </ul> </nav> </div> </div> </div>  </header>  <div class="govuk-width-container"> <main id="main" class="govuk-main-wrapper govuk-!-padding-bottom-9 govuk-!-padding-top-7"> <nav class="govuk-breadcrumbs govuk-!-margin-top-0 govuk-!-margin-bottom-5" aria-label="Breadcrumb"> <ol class="govuk-breadcrumbs__list"> <li class="govuk-breadcrumbs__list-item"> <a class="govuk-breadcrumbs__link govuk-!-margin-0" href="/">Home</a> </li> <li class="govuk-breadcrumbs__list-item"> <a class="govuk-breadcrumbs__link govuk-!-margin-0" href="/how-tos">How-tos and resources</a> </li> </ol> </nav> <div class="govuk-grid-row"> <div class="govuk-grid-column-two-thirds govuk-!-margin-bottom-7 govuk-!-padding-bottom-5" data-pagefind-body> <h1 class="govuk-heading-xl">Legal concerns (to be updated)</h1> <p class="govuk-body">
This information complements and updates the
<a href="https://www.gov.uk/government/publications/ai-playbook-for-the-uk-government" class="govuk-link">
AI Playbook for the UK Government
</a>
. It reflects the latest guidance and best practice. This will be updated as needed.</p> </div> </div> <div class="govuk-grid-row"> <div class="govuk-grid-column-one-third kh-sticky-sidebar kh-sticky-sidebar--with-back-to-top"> <on-this-page sidebar="true"></on-this-page> <div class="kh-back-to-top" data-astro-cid-qrl4wijt> <a class="govuk-link govuk-link--no-visited-state" href="#top" data-astro-cid-qrl4wijt> <svg role="presentation" focusable="false" class="kh-back-to-top__icon" xmlns="http://www.w3.org/2000/svg" width="13" height="17" viewBox="0 0 13 17" data-astro-cid-qrl4wijt> <path fill="currentColor" d="M6.5 0L0 6.5 1.4 8l4-4v12.7h2V4l4.3 4L13 6.4z" data-astro-cid-qrl4wijt></path> </svg>Back to top
</a> </div>  </div> <div class="govuk-grid-column-two-thirds kh-guidance--draft" id="content"><h2 class="govuk-heading-m" id="legalconsiderations">Legal considerations</h2>
<p class="govuk-body">Different types of AI and use cases will likely create different types of legal issues. To mitigate these, you should seek advice from government legal advisers who can help you navigate the design and use of AI in government.</p>
<p class="govuk-body">Many of the legal issues that surround AI are not new. For example, the ethical principles discussed in this playbook, such as fairness, discrimination, transparency and bias, have sound foundations in public and other law. Any ethical issues that your team identifies are also likely to be legal issues that your lawyers will be able to help guide you through.</p>
<p class="govuk-body">The <a class="govuk-link" href="#lawfulnessandpurposelimitation">lawfulness and purpose limitation</a> section explains how to ensure that personal data is processed lawfully, securely and fairly at all times. Your lawyers can advise you on that.</p>
<p class="govuk-body">You may face procurement and commercial issues when buying AI products. Alongside commercial colleagues, your lawyers can also help you navigate to those challenges.</p>
<p class="govuk-body">When you contact your legal team, you should explain your aims for the AI solution, what it will be capable of doing, and any potential risks you’re aware of. This will help you to understand, for example, if you need legislation to achieve what you want to do.</p>
<p class="govuk-body">It will also help to minimise the risk of your work:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">being challenged in court</p></li>
<li><p class="govuk-body">having unintended or unethical consequences</p></li>
<li><p class="govuk-body">having a negative impact on the people you want it to benefit</p></li>
</ul>
<h3 class="govuk-heading-s" id="examplelegalissues">Example legal issues</h3>
<p class="govuk-body">The following types of issues are designed to help you understand when you might want to consider getting legal advice. They should not be read as real legal advice and their application to any given scenario will depend on the specific facts. You should always consult your organisation’s lawyer.</p>
<h3 class="govuk-heading-s" id="dataprotection">Data protection</h3>
<p class="govuk-body">Data protection is a legal issue with potentially serious consequences if the government gets it wrong.</p>
<p class="govuk-body">Although your organisation will likely have a data protection officer, and there may also already be data protection experts in your team, your legal team can help you unpick some of the difficult data protection issues that are created by AI.</p>
<p class="govuk-body">Refer to the <a class="govuk-link" href="#dataprotectionandprivacy">data protection and privacy</a> section for more information.</p>
<h3 class="govuk-heading-s" id="contractualissues">Contractual issues</h3>
<p class="govuk-body">Your lawyers will help you draw up the contracts and other agreements for the procurement or licensing of AI tools. There may be special considerations for these contracts, including how to:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">deal with intellectual property</p></li>
<li><p class="govuk-body">ensure the level of transparency needed to help buyers understand their systems</p></li>
<li><p class="govuk-body">transfer a project to new or successor suppliers</p></li>
<li><p class="govuk-body">assist with the defence against any legal challenge</p></li>
</ul>
<p class="govuk-body">Contracts for technology services may need to incorporate procedures for system errors and outages that recognise the potential consequences of performance failures.</p>
<p class="govuk-body">It’s important that you consider appropriate contractual terms early on because this may, in part, drive decisions on the appropriate route to market. Refer to the <a class="govuk-link" href="/how-to/procurement">buying AI</a> section for more information.</p>
<h3 class="govuk-heading-s" id="intellectualpropertyincludingcopyright">Intellectual property, including copyright</h3>
<p class="govuk-body">Potential intellectual property issues with AI can be navigated with the help of your lawyers.</p>
<p class="govuk-body">You should consider at the outset:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">which parties will own which parts of any intellectual property generated during the project</p></li>
<li><p class="govuk-body">which parties will have ongoing rights to use any intellectual property that is generated, and on what basis</p></li>
<li><p class="govuk-body">how the balance of risk and liability should be determined between the parties, as this will be relevant to any claims for infringement of third-party intellectual property</p></li>
</ul>
<h3 class="govuk-heading-s" id="equalityissues">Equality issues</h3>
<p class="govuk-body">Lawyers can help you navigate the equality issues raised by the use of AI in government, such as obligations arising under the <a class="govuk-link" href="https://www.gov.uk/guidance/equality-act-2010-guidance">Equality Act 2010</a> and the <a class="govuk-link" href="https://www.gov.uk/government/publications/public-sector-equality-duty-guidance-for-public-authorities/public-sector-equality-duty-guidance-for-public-authorities">Public Sector Equality Duty</a>. Conducting an assessment of the equality impacts of your use of AI can also be one way to guard against bias, which is particularly important in the context of AI.</p>
<p class="govuk-body">If approached as early as before signing contracts, your legal advisers can help you to ensure the government is fulfilling its responsibilities to the public by assessing the impacts of the technology it’s using.</p>
<h3 class="govuk-heading-s" id="publiclawprinciples">Public law principles</h3>
<p class="govuk-body">Public law principles explain how public bodies should act rationally, fairly, lawfully and in compatibility with human rights. They are guidelines for public bodies on how to act within the law.</p>
<p class="govuk-body">Many of these public law principles overlap with the ethics set out in this guidance. As a result, your lawyers will likely be able to guide you on how to apply ethical principles based on their knowledge of public law, the court cases that have occurred, and the detail of the judgments.</p>
<p class="govuk-body">For example, public law involves a principle of procedural fairness. This is not so much about the decision that is eventually reached but about how a decision is arrived at. The transparency and explainability of the AI tool may well be key in being able to demonstrate that the procedure was fair. Similarly, an inability to determine how AI tools have arrived at their decisions or outputs may introduce risk into the decision-making process.</p>
<p class="govuk-body">Public law also considers rationality. Rationality may be relevant in testing the choice of an AI system, considering the features used in a system, and considering the outcomes of the system and the metrics used to test those outcomes.</p>
<p class="govuk-body">If you’re considering using AI in decision-making, here public law can also guide you. It can help you determine whether a particular decision should be delegated to a decision maker, rather than letting an AI tool make an automated decision. When operating in a regulated environment, such as a procurement process, automated decision-making or assessments could be subject to legal challenge if procedural fairness, lack of bias and rationality cannot be evidenced.</p>
<h3 class="govuk-heading-s" id="humanrights">Human rights</h3>
<p class="govuk-body">Public authorities must act in a way that is compatible with human rights. It’s possible that AI systems, especially those involving the use of personal data, may in some way affect at least one of an individual’s rights as set out in the <a class="govuk-link" href="https://www.coe.int/en/web/human-rights-convention">European Convention on Human Rights</a> (ECHR). The rights most likely to be impacted are Article 8 (right to a private and family life) and Article 10 (freedom of expression).</p>
<h3 class="govuk-heading-s" id="legislation">Legislation</h3>
<p class="govuk-body">Sometimes, in order to do something, a public authority needs a legislative framework. Your lawyers will be able to advise you whether your use of AI is within the current legal framework or needs new legislation.</p>
<p class="govuk-body">For example, the legislative framework might not allow the process you’re automating to be delegated to a machine, or it might provide for a decision to be made by a particular person.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Ensure you engage legal professionals at the outset of your AI project. They can help you navigate legal complexities and identify potential legal risks associated with data protection, contractual agreements, intellectual property, equality issues, and compliance with public law principles.</p></li>
<li><p class="govuk-body">Given the potential consequences of mishandling personal data, you should collaborate with legal experts to ensure you comply with data protection regulations and understand how to mitigate risks associated with data privacy and security.</p></li>
<li><p class="govuk-body">Work with legal experts to develop robust contracts and agreements for procuring or licensing AI tools, considering issues such as intellectual property rights, transparency levels, liability distribution, and procedures for addressing system errors or failures.</p></li>
<li><p class="govuk-body">Seek legal advice to determine whether your AI project aligns with existing legislative frameworks or requires new legislation. Understanding legislative constraints helps mitigate the risk of legal challenges and ensures you comply with legislative requirements.</p></li>
</ul>
<h2 class="govuk-heading-m" id="dataprotectionandprivacy">Data protection and privacy</h2>
<p class="govuk-body">AI-driven technologies offer significant benefits but they also pose the potential risk of harm to individuals and groups if they’re not implemented with specific focus on protecting individuals’ <a class="govuk-link" href="https://ico.org.uk/for-organisations/data-protection-fee/legal-definitions-fees/#data">personal data</a> and right to privacy.</p>
<p class="govuk-body">Be aware that organisations developing and deploying AI systems must consider the principles of data protection outlined in the <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/">UK General Data Protection Regulation (UK GDPR)</a> and the <a class="govuk-link" href="https://www.gov.uk/data-protection">Data Protection Act 2018</a> to minimise the risk of privacy intrusion from the outset.</p>
<p class="govuk-body">The UK data protection law applies irrespective of the type of technology used, so its basic principles of compliance will also apply to any AI system. The data protection principles most relevant to the use of AI are:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body"><a class="govuk-link" href="#accountability">accountability</a>, where that your organisation has clear ownership of risk and responsibility for mitigations and compliance</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#lawfulnessandpurposelimitation">lawfulness</a>, where you have an applicable lawful basis for processing personal data and ensure the processing is lawful under data protection or any other regulation</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#lawfulnessandpurposelimitation">purpose limitation</a>, to define why you’re processing personal data and only process data for that purpose</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#transparencyandindividualrights">transparency and individual rights</a>, where you’re open about what it uses personal data for, and your users can exercise their information rights</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#fairness">fairness</a>, to avoid processing personal data in ways that are detrimental, unexpected or misleading</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#dataminimisation">data minimisation</a>, to develop systems that process only the data that is needed for the task at hand</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#storagelimitation">storage limitation</a>, so that you don’t accumulate large amounts of personal data for unjustifiably long periods</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#humanoversight">human oversight</a>, to build in human oversight to automated decision-making</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#automateddecisionmakingadm">automated decision-making (ADM)</a>, where you consider whether using an automated decision system is appropriate</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="#accuracy">accuracy</a>, where you have steps in place to ensure the accuracy of AI-generated responses and data related to individuals</p></li>
<li><p class="govuk-body"><a class="govuk-link" href="/how-to/security">security</a>, to implement appropriate technical and organisational mitigations to protect sensitive and personal data</p></li>
</ul>
<p class="govuk-body">Data protection and privacy considerations require specialist expertise, so it’s crucial to involve relevant data protection, legal and other information governance professionals in AI projects from the outset to follow data protection by design principles.</p>
<h3 class="govuk-heading-s" id="accountability">Accountability</h3>
<p class="govuk-body">Accountability is a key principle that establishes ownership of risk, responsibility for mitigations, compliance with legislation, the ability to demonstrate compliance, and high standards for privacy.</p>
<p class="govuk-body">When planning AI solutions, you should:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">make strategic decisions on how any use of AI technology fits with your existing risk tolerance</p></li>
<li><p class="govuk-body">review your risk governance model to establish clear ownership of AI risks at a senior level</p></li>
<li><p class="govuk-body">implement measures to mitigate these risks and test their effectiveness</p></li>
<li><p class="govuk-body">make sure you identify residual risks and align them with your organisation’s risk threshold</p></li>
<li><p class="govuk-body">be collaborative, work transparently and demonstrate how you mitigate risks</p></li>
<li><p class="govuk-body">due to the evolving nature of AI technologies and new regulations, ensure you conduct regular reviews, with a view to making further iterations</p></li>
<li><p class="govuk-body">engage with internal data protection, privacy and legal experts from the outset</p></li>
</ul>
<p class="govuk-body"><a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/guide-to-accountability-and-governance/data-protection-by-design-and-default/">Data protection by design</a> is an important component of the UK GDPR risk-based approach. It requires you to integrate data protection safeguards into personal data processing activities throughout the AI product life cycle.</p>
<p class="govuk-body">This will ensure that you implement appropriate technical and organisational measures to protect <a class="govuk-link" href="https://ico.org.uk/for-organisations/data-protection-fee/legal-definitions-fees/#:~:text=compliance%20with%20them.-,Data%20subject,to%20whom%20personal%20data%20relates">data subject</a> rights, and comply with the <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/data-protection-principles/a-guide-to-the-data-protection-principles/">data protection principles</a> defined in the UK GDPR and Data Protection Act 2018.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-1">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Establish ownership of AI risks at a senior level.</p></li>
<li><p class="govuk-body">Integrate oversight of AI into your governance processes.</p></li>
<li><p class="govuk-body">Take a risk-based approach, defining risk appetite and following <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/guide-to-accountability-and-governance/data-protection-by-design-and-default/">principles of data protection by design and by default</a>.</p></li>
</ul>
<h3 class="govuk-heading-s" id="lawfulnessandpurposelimitation">Lawfulness and purpose limitation</h3>
<p class="govuk-body">Before implementing AI solutions, you need to undertake a <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/data-protection-impact-assessments-dpias/">data protection impact assessment (DPIA)</a>. This involves an assessment of data protection and privacy risks, and the implementation of appropriate technical and organisational measures to sufficiently mitigate them.</p>
<p class="govuk-body">Article 35(3)(a) of the UK GDPR requires you to undertake a DPIA if your use of AI involves any:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">systematic or extensive evaluation of personal data aspects based on automated processing, including profiling, on which decisions are made that produce legal or similarly significant effects</p></li>
<li><p class="govuk-body">large-scale processing of special categories of personal data</p></li>
<li><p class="govuk-body">systematic monitoring of publicly accessible areas on a large scale</p></li>
</ul>
<p class="govuk-body">The <a class="govuk-link" href="https://ico.org.uk/">Information Commissioner’s Office (ICO)</a> also requires a DPIA if your processing of personal data involves the use of innovative technologies. In your DPIA, you must:</p>
<ol class="govuk-list govuk-list--number govuk-list--spaced">
<li>describe the purpose of personal data processing activities</li>
<li>assess the necessity and proportionality of personal data processing</li>
<li>identify all <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/personal-information-what-is-it/what-is-personal-information-a-guide/">personal data</a>, including <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/a-guide-to-lawful-basis/lawful-basis-for-processing/special-category-data/#scd1">special category data</a>, that is being processed, including sources and flows of data</li>
<li>identify the <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/a-guide-to-lawful-basis/">valid lawful basis</a> under Article 6, and any <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/a-guide-to-lawful-basis/lawful-basis-for-processing/special-category-data/#scd3">additional special conditions</a> under Article 9 for special category data of the UK GDPR</li>
<li>identify your organisation’s role and obligations as a data controller and whether any data processors are involved</li>
<li>identify the stages when AI processes and automated decisions may have an impact on individuals</li>
<li>seek and document the views of individuals whose personal data is being processed. This includes finding out whether data subjects are aware that this processing is taking place</li>
<li>identify the stages when any human is involved in the decision-making process</li>
<li>consider any potential detriment to individuals due to bias or inaccuracy</li>
<li>document measures and safeguards put in place, and any residual levels of risk posed by the processing</li>
</ol>
<p class="govuk-body">The purpose for which data is collected and used has a significant effect on whether individuals perceive it as being invasive to privacy. A clear and well-defined articulation of this purpose from the outset will guide your deliberations about an applicable, lawful basis and the minimum personal data that is absolutely necessary to deploy the AI service.</p>
<p class="govuk-body">AI systems often reuse personal data for new purposes that are different from those for which it was originally collected. This may cause tension with the purpose limitation of the UK GDPR. Repurposing of personal data is only legitimate if a new purpose is compatible with the purpose for which the data was originally collected.</p>
<p class="govuk-body">When repurposing personal data, you should consider:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">whether the new purpose aligns with the data subjects’ expectations</p></li>
<li><p class="govuk-body">what type of personal data is involved</p></li>
<li><p class="govuk-body">what potential impact it will have on data subjects’ interests</p></li>
<li><p class="govuk-body">whether the data controller will need to adopt additional safeguards to ensure fairness and transparency</p></li>
</ul>
<p class="govuk-body">The DPIA process should identify personal data processing at each stage of the AI life cycle, from design to data acquisition and preparation, training, testing, deployment and monitoring. Although it’s common to characterise AI with large volumes of data, AI systems are able to directly perceive and evaluate their environment, and adapt to the data received. You should not underestimate AI’s interactive qualities, such as its ability to collect new data in real time from touchscreens and audiovisual inputs and adapt its responses and subsequent functions based on these inputs.</p>
<p class="govuk-body">When mapping personal data flows, you should identify the geographic location of each distinct processing activity because the processing of data outside the United Kingdom will increase the risk of losing the protection of UK data protection laws. Data controllers may need to bring in additional safeguards, such as <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/international-transfers/international-data-transfer-agreement-and-guidance/">international data transfer agreements</a>, if personal data is being processed in jurisdictions where the data protection regime is not deemed to be adequate and transfers of personal data are restricted under Article 46 of the UK GDPR.</p>
<p class="govuk-body">If your assessment indicates that there’s a high risk to the data protection rights of individuals, and that you’re unable to sufficiently reduce these risks despite mitigating actions, you must consult the ICO before you can start processing personal data.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-2">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">When building your team, seek support from data compliance professionals, including data protection, legal and privacy experts.</p></li>
<li><p class="govuk-body">Identify data processing operations and their purpose, and map personal data sources and flows.</p></li>
<li><p class="govuk-body">Determine whether personal data is necessary for each activity, and whether you’re processing special category data or children’s data.</p></li>
<li><p class="govuk-body">Identify the applicable lawful basis of your data processing and assess data protection and privacy risk through <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/data-protection-impact-assessments-dpias/">DPIAs</a> and <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/a-guide-to-lawful-basis/lawful-basis-for-processing/legitimate-interests/">legitimate interest assessments</a>.</p></li>
<li><p class="govuk-body">If data protection and privacy risks remain high even after mitigations, <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/data-protection-impact-assessments-dpias/do-we-need-to-consult-the-ico/">consult with the ICO</a>.</p></li>
<li><p class="govuk-body">Identify any processing outside the UK to take additional safeguards to protect personal data in jurisdictions where the data protection regime may not be adequate.</p></li>
<li><p class="govuk-body">Assess any changes in the purpose of your AI system and make sure your AI system remains compliant and lawful.</p></li>
</ul>
<h3 class="govuk-heading-s" id="transparencyandindividualrights">Transparency and individual rights</h3>
<p class="govuk-body">In addition to the ethical reasons for seeking transparency, organisations need to be transparent about how they process personal data in an AI system so that individuals can effectively exercise the rights granted to them by the UK GDPR.</p>
<p class="govuk-body">The UK GDPR requires data controllers to:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">provide information to users in a concise, transparent, intelligible and easily accessible form using clear and plain language</p></li>
<li><p class="govuk-body">be transparent about the purpose for processing personal data, retention periods and third parties involved in the processing activity</p></li>
<li><p class="govuk-body">be transparent about the existence of automated decision-making, providing meaningful information about the logic involved, and about the significance and envisaged consequences for the data subject of processing in this way</p></li>
<li><p class="govuk-body">provide a clear explanation of the results these systems produce</p></li>
<li><p class="govuk-body">uphold individuals’ rights, including the right of access to the personal data that you hold on them, and have a simple and clear process to exercise their right to correction and to object to the processing of their personal data at any time</p></li>
</ul>
<p class="govuk-body">The transparency principle applies to personal data collected from all sources, including the interactive qualities of AI systems that have the ability to collect new data, which may include text and audiovisual inputs. For example, if you’re using facial recognition technology for public area monitoring, you need to be transparent by clearly informing data subjects. You can do this with clear signage and information about relevant data controllers, what information is collected, the purpose and legal basis of processing, and for how long the data is kept.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-3">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Explain your system in plain English.</p></li>
<li><p class="govuk-body">Be transparent about the purpose for processing personal data, retention periods and third parties involved in the processing activity.</p></li>
<li><p class="govuk-body">Be transparent about the existence and nature of automated decision-making, using the <a class="govuk-link" href="https://www.gov.uk/government/collections/algorithmic-transparency-recording-standard-hub">Algorithmic Transparency Recording Standard Hub</a> where required or on a voluntary basis as best practice.</p></li>
<li><p class="govuk-body">Provide a clear explanation of the results these systems produce, following guidance such as the ICO’s <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/">explaining decisions made with AI</a>.</p></li>
</ul>
<h3 class="govuk-heading-s" id="fairness">Fairness</h3>
<p class="govuk-body">Fairness in processing is another principle under the <a class="govuk-link" href="https://www.legislation.gov.uk/ukpga/2018/12/contents/enacted">UK GDPR</a> which applies to AI systems that process personal data. In the context of data protection legislation, fairness means that ‘you should only process personal data in ways that people would reasonably expect and not use it in any way that could have unjustified adverse effects on them’.</p>
<p class="govuk-body"><a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/data-protection-impact-assessments-dpias/">DPIAs</a> are the main tool to help you consider the risks to the rights and freedoms of individuals, including the potential for any significant social or economic disadvantage. DPIAs also help demonstrate whether your processing is necessary to achieve your purpose, and if they are proportionate and fair.</p>
<p class="govuk-body">The Responsible Technology Adoption Unit (RTA) in DSIT published the results of its <a class="govuk-link" href="https://www.gov.uk/government/publications/public-attitudes-to-data-and-ai-tracker-survey-wave-3">public attitudes to data and AI survey</a> in December 2023. This report found that people’s comfort with the use of AI greatly depends on the specific context. Perceptions of the need for AI governance also vary considerably by sector, with a substantial proportion of the public prioritising careful management of AI used in healthcare, the military, or in banking and finance.</p>
<p class="govuk-body">You must make sure that AI systems do not process personal data in ways that are unduly detrimental, unexpected or misleading to the individuals concerned. If AI systems infer data about people, you need to ensure that the system is accurate and not discriminatory. You need to uphold the right to be informed for individuals whose personal data is used at any stage of the development and deployment of AI systems. This is part of fulfilling the transparency and fairness principles.</p>
<p class="govuk-body">Data protection aims to protect individuals’ rights and freedoms with regard to the processing of their personal data, not just their information rights. This includes the right to privacy but also the right to non-discrimination. For example, computer vision technologies such as facial recognition have raised concerns due to the risk of errors in matching faces. This technology has proven to be less accurate when used on women and people of colour, producing biased results. Ultimately, this can create discrimination, raising fundamental rights concerns because of the disadvantage to some individuals whose facial images are captured and processed.</p>
<p class="govuk-body">People’s facial images constitute biometric data. This is personal data because it’s the result of specific technical processing related to physical, physiological or behavioural characteristics of a natural person, which can confirm the unique identification of the person. Facial images may fall into the <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/a-guide-to-lawful-basis/lawful-basis-for-processing/special-category-data/#scd1">special categories of personal data</a> because they’re likely to reveal sensitive characteristics such as racial or ethnic origin, and so require enhanced protection and additional safeguards.</p>
<p class="govuk-body">Biometric data is also considered special category data when processed for the purposes of identification. You must ensure that the technologies used to capture and process this data are overt, accurate, proportionate, fair and deploy a narrow ‘zone of recognition’. For example, if someone walks past a camera and their image does not meet the threshold for a potential match, their data needs to be promptly deleted.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-4">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Identify the risks to the rights and freedoms of individuals through <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/data-protection-impact-assessments-dpias/">DPIAs</a> and assess whether your processing is necessary, proportionate and fair to achieve your purpose.</p></li>
<li><p class="govuk-body">Use the ICO’s <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/ai-and-data-protection-risk-toolkit/">AI and data protection risk toolkit</a> to reduce the risks to individuals’ rights and freedoms.</p></li>
<li><p class="govuk-body">Mitigate risks using the ICO’s <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/how-do-we-ensure-fairness-in-ai/what-about-fairness-bias-and-discrimination">guidance on fairness, bias and discrimination in AI systems</a>.</p></li>
<li><p class="govuk-body">Provide users with clear reassurance that you’re upholding their right to privacy, including simple processes to exercise their rights in clear <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/the-right-to-be-informed/what-methods-can-we-use-to-provide-privacy-information/">privacy notices</a>.</p></li>
<li><p class="govuk-body">Address any objections from users, including those related to solely automated decisions, or where there’s a significant legal impact,&nbsp;by implementing safeguards such as meaningful human intervention, or an effective process to obtain and consider individuals’ views and corrections of factual errors.</p></li>
</ul>
<h3 class="govuk-heading-s" id="dataminimisation">Data minimisation</h3>
<p class="govuk-body">The data minimisation principle requires you to identify the minimum amount of personal data you need to fulfil your purpose, and to only process that information and no more. This does not mean that AI tools should not process personal data, but if you can achieve the same outcome by processing a smaller amount of personal data then the data minimisation principle requires you to do so.</p>
<p class="govuk-body">Retaining data that is not strictly necessary is a risk to the individuals from whom the data is derived. Excluding irrelevant data prevents algorithms from identifying correlations that lack significance or are coincidental. There are a number of techniques that you can adopt to develop AI systems that process only the data you need while still remaining functional.</p>
<p class="govuk-body">For example, you can consider using privacy-enhancing technologies (PETs) to offer stronger protections and preserve data privacy while enabling the effective use of data. Some PETs provide new tools for anonymisation, and some enable collaborative analysis on privately-held data sets, allowing data to be used without disclosing copies of the data.</p>
<p class="govuk-body">PETs are multipurpose, so you can use them to reinforce data governance choices, or as tools for data collaboration and greater accountability through audits. A data-focused example solution is to create ‘synthetic data’. This is an artificial data set that does not include any actual data on ‘real’ individuals but mirrors in characteristics and proportional relationships all statistical aspects of the original data set.</p>
<p class="govuk-body">You must be aware that advanced AI models can sometimes re-identify individuals by correlating multiple pseudonymized data points. The DPIA process must explicitly assess this re-identification risk.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-5">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Justify your use of personal data, using your DPIA to think about the problem you’re solving so that you settle with the minimum personal data that’s required. Less personal data means less risk.</p></li>
<li><p class="govuk-body">Reduce the risk of individuals being identified through the processing of their personal data by using appropriate de-identification techniques, such as redaction, pseudonymisation and encryption.</p></li>
<li><p class="govuk-body">Refer to the ICO guidance on <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/data-sharing/privacy-enhancing-technologies/">privacy-enhancing technologies (PETs)</a>.</p></li>
</ul>
<h3 class="govuk-heading-s" id="storagelimitation">Storage limitation</h3>
<p class="govuk-body">The UK GDPR states that you should only hold personal data as long as you can reasonably justify it for the purpose of your processing, and that you should not retain personal data longer than you need it. You must consider:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">what personal data the technology will hold</p></li>
<li><p class="govuk-body">why you have it and what it’s used for</p></li>
<li><p class="govuk-body">whether you can justify keeping it for that period of time</p></li>
</ul>
<p class="govuk-body">You should map all personal data flows through every stage of development, testing and deployment, and utilise data minimisation, anonymisation techniques and eventual deletion to irreversibly transform or remove personal data.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-6">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Use data minimisation and <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/data-sharing/anonymisation/">anonymisation techniques</a> as needed to remove or irreversibly transform personal data where possible.</p></li>
<li><p class="govuk-body">Be transparent about the length of personal data retention in privacy notices.</p></li>
</ul>
<h3 class="govuk-heading-s" id="humanoversight">Human oversight</h3>
<p class="govuk-body">It is possible to use AI systems for automated decision-making, which is where the system makes a decision automatically without any human involvement. However, this may infringe on the UK GDPR. Article 22 currently prohibits decisions based solely on automated processing that have <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/automated-decision-making-and-profiling/what-does-the-uk-gdpr-say-about-automated-decision-making-and-profiling/#:~:text=by%20automated%20means.-,What%20types%20of%20decision%20have%20a%20legal%20or%20similarly%20significant,law%2C%20such%20as%20housing%20benefit.">legal or similarly significant consequences</a> for individuals. Services using AI that affect a person’s legal status or their legal rights must only use AI to support decisions that must be made by a human decision maker.</p>
<p class="govuk-body">AI systems need to introduce deliberation processes into all stages of the life cycle so that the abilities of humans and machines are combined to reach the best results when performing tasks. The human input must still be meaningful. Several factors determine how much human involvement there should be in AI systems, such as the complexity of the output, its potential impact, and the amount of specialist human knowledge required for specialist areas such as legal and medical.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-7">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Design, document and assess the stages when meaningful human review processes are incorporated and what additional information will be taken into consideration when making the final decision.</p></li>
<li><p class="govuk-body">Use the ICO guidance on <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/automated-decision-making-and-profiling/what-does-the-uk-gdpr-say-about-automated-decision-making-and-profiling/">automated decision-making under UK GDPR</a> for more clarity on types of decisions that have a legal or similarly significant effect.</p></li>
</ul>
<h3 class="govuk-heading-s" id="accuracy">Accuracy</h3>
<p class="govuk-body">Accuracy in the context of data protection requires that personal data is not factually incorrect or misleading, and, where necessary, is corrected, deleted and kept up to date without delay.</p>
<p class="govuk-body">You should not treat AI outputs as factual information about the individual, but instead consider these as a statistically-informed guess. You also need to factor in the possibility of outputs being incorrect and the impact this may have on any decisions.</p>
<p class="govuk-body">You need to make it explicit that the outputs of your AI systems are statistically informed guesses rather than facts, including information about the source of the data and how the inference has been generated.</p>
<h3 class="govuk-heading-s" id="automateddecisionmakingadm">Automated decision-making (ADM)</h3>
<p class="govuk-body"><strong>Definition and examples</strong></p>
<p class="govuk-body">Automated decision-making (ADM) is the process of making a decision by automated means using algorithms or computer systems. Its use is increasing quickly to process and make decisions on a large scale. ADM can be used to make decisions based on pre-defined rules, or can be powered by AI and machine learning.</p>
<p class="govuk-body">Decisions made by automated means do not always affect individuals, as in the example of traffic signal optimisation systems that automatically adjust the timing of traffic lights at intersections. Here, the system makes decisions about traffic patterns and not about people.</p>
<p class="govuk-body">Some automated decisions may affect individuals without using their personal data, such as dynamic transport pricing systems which adjust ticket prices based on demand, timing and popularity. Both of these examples have lower risks to individuals.</p>
<p class="govuk-body">Higher risk applications of automated decision-making are when these decisions may have legal or similar significant effects on individuals. An example of this is when automated decisions are used to assess eligibility for state benefits, as approval or denial of financial support can directly affect a person. These decisions can have legal consequences, such as appeals or investigations. Such automated decisions use personal data and have significant impact on individuals.</p>
<p class="govuk-body">Higher risk applications of ADM that process personal data and make decisions with legal or similarly significant impact on individuals are subject to the provisions of the UK data protection legislation.</p>
<p class="govuk-body">Solely automated systems are typically used for routine, repetitive tasks while automated decisions with human oversight are applied in more complex situations that may have significant consequences for data subjects. Profiling, which is a form of automated processing of personal data that makes predictions based on characteristics and patterns of behaviours with a margin of error, may be used to inform human decisions. Fairness, transparency and accountability need to be key considerations for profiling to be lawful and ethical.</p>
<p class="govuk-body">Automated decision-making can be useful for service providers and users by speeding up processes and reducing backlogs, but there are potential risks that need to be taken into consideration.</p>
<p class="govuk-body">The use of automated decision-making, how it works and how it affects people is not always obvious. The decisions made by automated means may lead to significant adverse effects for some individuals.</p>
<p class="govuk-body">It is very important to consider whether using an automated decision system is appropriate in your context. A process won’t be considered fully automated if someone interrogates the decision-making, weighs up and interprets the result with the discretion to alter it before applying it to the individual. If further automated processing such as profiling was used at any stage, that could reduce the range of decisions to the extent that human involvement could never be meaningful.</p>
<p class="govuk-body">The extent to which human engagement is required for your context depends on factors such as the complexity of the system’s output, the potential impact on the individual, and whether specialist expertise, such as legal or medical knowledge, is required. Simply applying the decision taken by the automated system, without meaningful human involvement, interrogation and consideration, is a token gesture and does not constitute meaningful human involvement.</p>
<p class="govuk-body">Individuals have the right to transparency and fairness in how decisions that affect them are made, especially when those decisions have legal or similarly significant effects. Additionally, automated decision-making carries significant risks to accuracy, particularly when decisions are based on incomplete, outdated, or biased data. In such cases, it is essential that a human is meaningfully involved before a final decision is made.</p>
<p class="govuk-body"><strong>Data (Use and Access) Act 2025 and the UK GDPR</strong></p>
<p class="govuk-body"><a class="govuk-link" href="https://www.legislation.gov.uk/ukpga/2025/18/section/80/enacted">Section 80 of the Data (Use and Access) Act 2025</a> has introduced changes to the Article 22 provisions of the UK GDPR.</p>
<p class="govuk-body">According to the Data Act, a solely automated decision is defined as a decision made entirely through automated processing without any meaningful human involvement. This decision will also have either a legal effect, such as the approval or denial of a benefit, contract, or service, or a similarly significant impact, such as affecting someone’s financial situation, access to healthcare, or employment opportunities. The Data Act permits these automated decisions as long as safeguards are provided for the individuals affected where they:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">are informed by the data controller about the existence of automated decision-making</p></li>
<li><p class="govuk-body">receive meaningful information from the data controller about the logic involved, the significance, and the envisaged consequences for the data subject</p></li>
<li><p class="govuk-body">request human intervention</p></li>
<li><p class="govuk-body">express their point of view where the decision is necessary for a contract or based on explicit consent</p></li>
<li><p class="govuk-body">contest the decision and obtain an explanation where the decision is necessary for a contract or based on explicit consent</p></li>
</ul>
<p class="govuk-body">The Act restricts solely automated decision-making using <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/special-category-data/what-is-special-category-data/">special categories of personal data</a> as described in Article 9(1) of the UK GDPR. This includes personal data that relates to health, employment, political belief, race, religion and gender, unless:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">the individual has explicitly agreed to the automated decision (given explicit consent)</p></li>
<li><p class="govuk-body">there are reasons of substantial public interest</p></li>
<li><p class="govuk-body">the automated decision is required or allowed by law, and the processing meets specific legal safeguards listed above</p></li>
</ul>
<p class="govuk-body">The <a class="govuk-link" href="https://www.gov.uk/government/publications/ethics-transparency-and-accountability-framework-for-automated-decision-making/ethics-transparency-and-accountability-framework-for-automated-decision-making">ethics, transparency and accountability framework for automated decision-making</a> published by DSIT provides guidance to help you with the safe, sustainable and ethical use of automated or algorithmic decision-making. It provides definitions, examples, risks and a framework for responsible and fair use. The Information Commissioner’s Office has also published useful guidance in relation to compliance with the data protection legislation, which can be found at <a class="govuk-link" href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/automated-decision-making-and-profiling/what-is-automated-individual-decision-making-and-profiling/#id2">what is ADM?</a></p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="automationbias">Automation Bias</h4>
<p class="govuk-body">Automation bias describes the potential for individuals involved in augmented assisted decision-making to rely too heavily on the decisions recommended by the automated system, and a reluctance to challenge decisions that they believe may be inaccurate.</p>
<p class="govuk-body">This bias can have a negative impact on accuracy and safety for augmented assisted decision systems. It can erode the value of having a human in the loop and the human operator’s ability to have meaningful control over a system.</p>
<p class="govuk-body">As augmented assisted decision-making is used in areas which may have more significant consequences, it is necessary to ensure that human interactions are meaningful, and that the risk of automation bias is understood and mitigated. Over-reliance by a human decision-maker on an AI-generated recommendation or prediction may render the decision susceptible to legal challenge, particularly if it can be established that the human has failed to exercise any real judgment of their own or has not understood how the AI-generated recommendation or prediction was arrived at.</p>
<p class="govuk-body">There are multiple human, contextual and design factors that may increase the risk of automation bias. These include:</p>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">human factors such as knowledge gaps in human reviewers, or a lack of real-world experience</p></li>
<li><p class="govuk-body">contextual factors such as time pressure and task complexity</p></li>
<li><p class="govuk-body">design factors such as the omission of confidence scores</p></li>
</ul>
<p class="govuk-body">The risk of automation bias may be mitigated in some instances through design and process changes, such as by displaying the confidence of automated decisions and recommendations, or prompts to ensure ongoing engagement with tasks. Additional confirmations and notifications of human accountability in the process can also help.</p>
<p class="govuk-body">Adequate mitigations will depend on the specific application of ADM in your process. Your teams should assess to ensure mitigations are effective. If they are not, you will need to decide whether ADM of any kind is appropriate for your project.</p>
<h4 class="govuk-body-s govuk-!-font-weight-bold" id="practicalrecommendations-8">Practical recommendations</h4>
<ul class="govuk-list govuk-list--bullet govuk-list--spaced">
<li><p class="govuk-body">Consider whether using an automated decision system is appropriate in your context.</p></li>
<li><p class="govuk-body">Provide clear information explaining whether&nbsp; personal data is used and whether automated decisions are made, especially if the automated decision might impact outcomes relating to an individual. The <a class="govuk-link" href="https://www.bing.com/ck/a?!&&p=681a407d7533ca6777392489b5816476253d57b733291891ef7d34e1f2f26907JmltdHM9MTc0OTY4NjQwMA&ptn=3&ver=2&hsh=4&fclid=18b7d836-91f2-6fef-261a-cdc490496e82&psq=Algorithmic+Transparency+Recording+Standard&u=a1aHR0cHM6Ly93d3cuZ292LnVrL2dvdmVybm1lbnQvY29sbGVjdGlvbnMvYWxnb3JpdGhtaWMtdHJhbnNwYXJlbmN5LXJlY29yZGluZy1zdGFuZGFyZC1odWI&ntb=1">Algorithmic Transparency Recording Standard Hub</a> is a mandatory tool for government organisations that helps with being open about automated decisions.</p></li>
<li><p class="govuk-body">Provide simple means for individuals to submit feedback, raise objections and request human intervention on automated decision making processes to engage with decisions that may affect them.</p></li>
<li><p class="govuk-body">Implement meaningful human intervention or an effective process to obtain and consider individuals’ views and the correction of factual errors. The human should weigh up and interpret the result of an automated recommendation with the discretion to alter it.</p></li>
<li><p class="govuk-body">Be mindful of potential biases and inaccuracies in data and algorithms. Involve diverse teams in development and take appropriate steps to assess and analyse any impact on those with protected characteristics.</p></li>
<li><p class="govuk-body">Where necessary to satisfy obligations under the Equalities Act 2010 (or equivalent legislation in Northern Ireland) and undertake <a class="govuk-link" href="https://www.gov.uk/government/publications/data-ethics-framework/data-ethics-framework-2020">ethical risk assessments</a></p></li>
<li><p class="govuk-body">Consider regular audits and reviews of automated systems to identify potential biases or errors within the automated decision-making systems.</p></li>
<li><p class="govuk-body">Refer to the <a class="govuk-link" href="https://www.gov.uk/government/publications/ethics-transparency-and-accountability-framework-for-automated-decision-making/ethics-transparency-and-accountability-framework-for-automated-decision-making">ethics, transparency and accountability framework for automated decision-making</a>, which provides a framework for the ethical and safe use of ADM in the public sector. The framework emphasises testing, fairness, responsibility, data protection, transparency, legal compliance, and future-proofing.</p></li>
<li><p class="govuk-body">Refer to the Information Commissioner’s Office guidance, with specific focus on the legal requirements of the UK GDPR, Data (Use and Access) Act 2025 regarding ADM and profiling. Be mindful of recent changes in the legislation and look out for <a class="govuk-link" href="https://ico.org.uk/about-the-ico/what-we-do/legislation-we-cover/data-use-and-access-act-2025/the-data-use-and-access-act-2025-duaa-summary-of-the-changes/data-protection/#automated">upcoming guidance from the Information Commissioner’s Office</a>.</p></li>
</ul></div> </div> </main> </div>  <footer data-astro-cid-sckkx6r4> <div class="govuk-width-container" data-astro-cid-sckkx6r4> <send-feedback data-astro-cid-sckkx6r4="true"></send-feedback> </div> <div class="govuk-footer" data-astro-cid-sckkx6r4> <div class="govuk-width-container" data-astro-cid-sckkx6r4> <div class="govuk-footer__meta" data-astro-cid-sckkx6r4> <div class="govuk-footer__meta-item govuk-footer__meta-item--grow" data-astro-cid-sckkx6r4> <h2 class="govuk-visually-hidden" data-astro-cid-sckkx6r4>Support links</h2> <ul class="govuk-footer__inline-list" data-astro-cid-sckkx6r4> <li class="govuk-footer__inline-list-item" data-astro-cid-sckkx6r4> <a class="govuk-footer__link" href="/site-map" data-astro-cid-sckkx6r4>Site map</a> </li> <li class="govuk-footer__inline-list-item" data-astro-cid-sckkx6r4> <a class="govuk-footer__link" href="/accessibility" data-astro-cid-sckkx6r4>Accessibility</a> </li> <li class="govuk-footer__inline-list-item" data-astro-cid-sckkx6r4> <a class="govuk-footer__link" href="mailto:ai-knowledge-hub@dsit.gov.uk" data-astro-cid-sckkx6r4>Contact us</a> </li> </ul> <svg aria-hidden="true" focusable="false" class="govuk-footer__licence-logo" viewBox="0 0 483.2 195.7" height="17" width="41" data-astro-cid-sckkx6r4> <path fill="currentColor" d="M421.5 142.8V.1l-50.7 32.3v161.1h112.4v-50.7zm-122.3-9.6A47.12 47.12 0 0 1 221 97.8c0-26 21.1-47.1 47.1-47.1 16.7 0 31.4 8.7 39.7 21.8l42.7-27.2A97.63 97.63 0 0 0 268.1 0c-36.5 0-68.3 20.1-85.1 49.7A98 98 0 0 0 97.8 0C43.9 0 0 43.9 0 97.8s43.9 97.8 97.8 97.8c36.5 0 68.3-20.1 85.1-49.7a97.76 97.76 0 0 0 149.6 25.4l19.4 22.2h3v-87.8h-80l24.3 27.5zM97.8 145c-26 0-47.1-21.1-47.1-47.1s21.1-47.1 47.1-47.1 47.2 21 47.2 47S123.8 145 97.8 145" data-astro-cid-sckkx6r4></path> </svg> <span class="govuk-footer__licence-description" data-astro-cid-sckkx6r4>
All content is available under the
<a class="govuk-footer__link" href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/" rel="license" data-astro-cid-sckkx6r4>Open Government Licence v3.0</a>, except where otherwise stated
</span> </div> <div class="govuk-footer__meta-item" data-astro-cid-sckkx6r4> <a class="govuk-footer__link govuk-footer__copyright-logo" href="https://www.nationalarchives.gov.uk/information-management/re-using-public-sector-information/uk-government-licensing-framework/crown-copyright/" data-astro-cid-sckkx6r4>© Crown copyright</a> </div> </div> </div> </div> </footer> <script type="module" src="/_astro/Layout.astro_astro_type_script_index_1_lang.DKaNH1GW.js"></script> </body></html> <script type="module">window.addEventListener("load",()=>{document.querySelectorAll(".analytics-on-this-page-link").forEach(e=>{e.addEventListener("click",n=>{posthog.capture("kh_contents_link_clicked",{guidance_page_name:n.currentTarget.textContent})})})});</script> <script type="module">const t=document.querySelector("on-this-page");window.addEventListener("message",function(e){typeof e.data?.content<"u"&&(document.querySelector("#content").innerHTML=e.data.content,document.querySelector("h1").textContent=e.data.title||"[Title goes here]",t.updateHeadings())});</script> <script type="module" src="/_astro/_...slug_.astro_astro_type_script_index_2_lang.Pa818wHY.js"></script>